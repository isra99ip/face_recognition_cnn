# üåç **FaceID en el Aula: IA para Identificaci√≥n Facial en Tiempo Real**

[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-green.svg)](https://www.python.org/downloads/)
[![TensorFlow Lite](https://img.shields.io/badge/TensorFlow-Lite-yellow.svg)](https://www.tensorflow.org/lite)
[![Android 8+](https://img.shields.io/badge/android-8%2B-blue.svg)](https://developer.android.com/)
[![UAC Cusco](https://img.shields.io/badge/UAC-Cusco-orange.svg)](https://uacusco.edu.pe/)

> Proyecto acad√©mico integrando **Visi√≥n Computacional, Deep Learning y Computaci√≥n M√≥vil**: demuestra c√≥mo un modelo CNN puede ser desplegado eficientemente en Android usando TensorFlow Lite.
> Implementado bajo el marco **CRISP-ML** y optimizado con **TensorFlow Lite**.

---

## üñºÔ∏è Im√°genes de Referencia

<p align="center">
  <img src="docs/img/diagrama_crispml.png" width="350" alt="Flujo CRISP-ML">
  <img src="docs/img/demo_mobile.gif" width="200" alt="Demo Android">
  <img src="docs/img/resultados.png" width="350" alt="Resultados">
</p>

*(Puedes cambiar estas rutas o sustituir por tus propias capturas: diagrama, demo y resultados.)*

---

## üß≠ Descripci√≥n General

**FaceID en el Aula** es un sistema de identificaci√≥n facial dise√±ado para reconocer miembros de un grupo utilizando √∫nicamente la c√°mara de un m√≥vil Android.  
El modelo emplea **MobileNetV2**, ajustado (*fine-tuning*) sobre un dataset personalizado y optimizado mediante **cuantizaci√≥n (float16/INT8)** para un rendimiento m√≥vil sin conexi√≥n.

üí° El objetivo es demostrar todo el ciclo de *Machine Learning Engineering* ‚Äî recolecci√≥n de datos, entrenamiento, optimizaci√≥n y despliegue ‚Äî siguiendo buenas pr√°cticas de ingenier√≠a.

---

## üß† Componentes Principales

| Etapa                | Herramienta/Librer√≠a           | Prop√≥sito                                   |
|----------------------|-------------------------------|---------------------------------------------|
| **Captura de Datos** | OpenCV                        | Recolecci√≥n de im√°genes faciales            |
| **Preprocesamiento** | Haar Cascade / Dlib           | Detecci√≥n y recorte autom√°tico de rostros   |
| **Modelado CNN**     | TensorFlow + Keras            | Entrenamiento/transfer learning             |
| **Optimizaci√≥n**     | TensorFlow Lite               | Conversi√≥n y cuantizaci√≥n para m√≥viles      |
| **App M√≥vil**        | Kotlin + CameraX + TFLite     | Inferencia en tiempo real                   |
| **Visualizaci√≥n**    | GitHub Pages + Chart.js       | Presentaci√≥n interactiva de m√©tricas        |

---

## ‚öôÔ∏è Requisitos del Entorno

```bash
# Crear entorno virtual (Linux/macOS)
python -m venv .venv && source .venv/bin/activate
# En Windows:
.venv\Scripts\activate

pip install --upgrade pip
pip install opencv-python-headless tensorflow==2.16.1 tensorflow-model-optimization \
            scikit-learn matplotlib pandas jupyter onnx onnxruntime tflite-support
```

- Python ‚â• 3.10
- GPU CUDA (opcional para acelerar entrenamiento)
- Android Studio Iguana o superior
- Dataset ‚â• 500 im√°genes totales (m√≠nimo 100 por persona)

---

## üß© Estructura del Proyecto

```
faceid-aula/
‚îú‚îÄ 1_data_collection/        # Captura de im√°genes
‚îú‚îÄ 2_data_prep/              # Preprocesamiento y partici√≥n
‚îú‚îÄ 3_model/                  # Entrenamiento/exportaci√≥n del modelo
‚îú‚îÄ 4_mobile_app_android/     # App Android (CameraX + TFLite)
‚îú‚îÄ models/                   # Modelos .h5 / .tflite optimizados
‚îú‚îÄ data/                     # Datos (train/val/test)
‚îî‚îÄ docs/                     # Infograf√≠a web (GitHub Pages)
```

---

## üîÅ Pipeline de Ejecuci√≥n

```bash
# 1Ô∏è‚É£ Captura de rostros (m√≠nimo 100 im√°genes/persona)
python 1_data_collection/capture_opencv.py --person PersonaA --n 150

# 2Ô∏è‚É£ Recorte, normalizaci√≥n y divisi√≥n del dataset
python 2_data_prep/detect_crop.py
python 2_data_prep/split_dataset.py

# 3Ô∏è‚É£ Entrenamiento, evaluaci√≥n y exportaci√≥n TFLite
python 3_model/train_mobilenetv2.py
python 3_model/eval_report.py
python 3_model/tflite_convert.py
```

Se generan:
- Matriz de confusi√≥n (`models/confusion_matrix.csv`)
- Reporte de clasificaci√≥n (Precision, Recall, F1)
- Modelos finales (.h5 y .tflite)

---

## üìä M√©tricas Clave

| Indicador         | Objetivo          | Descripci√≥n                           |
|-------------------|------------------|---------------------------------------|
| Accuracy (Test)   | ‚â• 90%            | Precisi√≥n general del modelo          |
| F1-Score          | ‚â• 0.90           | Balance entre precisi√≥n y exhaustividad |
| Latencia Android  | ‚â§ 500 ms/frame   | Tiempo promedio de inferencia         |
| Tama√±o modelo     | ‚â§ 20 MB          | Ideal para ejecuci√≥n local            |
| FPS               | ‚â• 10             | Fluidez aceptable en m√≥viles          |

Con MobileNetV2 y un dataset balanceado, se alcanzan accuracies del 94‚Äì97% (5 clases).

---

## üì± Despliegue M√≥vil (Android)

**Caracter√≠sticas:**
- Interfaz ligera con CameraX
- Procesamiento 100% local, sin conexi√≥n
- Etiquetado en pantalla por rostro con probabilidad
- Medici√≥n autom√°tica de latencia por frame
- Registro de logs en SQLite o Firebase Local

**Tecnolog√≠as:**
- Kotlin (nativo)
- TensorFlow Lite Interpreter
- Modelo: `faceid_best_float16.tflite`
- Compatibilidad: Android 8.0 (API 24)+

**Configuraci√≥n:**
1. Abre la carpeta del proyecto Android en Android Studio:
   ```
   4_mobile_app_android/Android/
   ```
2. Sigue las instrucciones en el archivo `README_android_full.md`.

---

## üß¨ Innovaciones T√©cnicas

‚úÖ Cuantizaci√≥n h√≠brida: float16 e INT8 para m√°xima eficiencia  
‚úÖ Data Augmentation inteligente: rotaci√≥n, brillo y simetr√≠a aleatoria  
‚úÖ Explicabilidad (XAI): mapas Grad-CAM para visualizaci√≥n de decisi√≥n  
‚úÖ Integraci√≥n Edge TPU: compatibilidad con Coral USB Accelerator y RPi4  
‚úÖ Seguridad biom√©trica local: embeddings cifrados (AES-256)  
‚úÖ Inferencia h√≠brida: soporte opcional en servidor Flask o API REST

---

## üß† Futuras Mejoras

- üì∏ Detecci√≥n multi-rostro con bounding boxes din√°micos
- üîä Integraci√≥n con VoiceID (reconocimiento de voz)
- üß© Reducci√≥n de sesgo de dataset (normalizaci√≥n de tono/fondo)
- ‚òÅÔ∏è Sincronizaci√≥n en la nube (Firebase + almacenamiento privado)
- üß† Migraci√≥n a Vision Transformers (ViT) o EfficientNet-Lite

---

## üåà Infograf√≠a Interactiva (GitHub Pages)

Incluye:
- Presentaci√≥n del problema y objetivos
- Diagrama del flujo CRISP-ML
- Arquitectura MobileNetV2 y capas entrenadas
- Curvas de entrenamiento/evaluaci√≥n
- Resultados visuales y v√≠deo demostrativo

Archivo principal: `docs/index.html`  
Publicaci√≥n autom√°tica en GitHub Pages tras commit en la rama `main`.

---

## üìö Referencias T√©cnicas

- Sandler, M. et al. (2018). MobileNetV2: Inverted Residuals and Linear Bottlenecks.
- [TensorFlow Lite Docs](https://www.tensorflow.org/lite)
- CRISP-ML(Q): Springer (2021)
- [Android CameraX API](https://developer.android.com/training/camerax)

---

## üßë‚Äçüíª Autores

**Proyecto:** FaceID en el Aula  
**Facultad:** Ingenier√≠a de Sistemas ‚Äì UAC, Cusco  
**Versi√≥n:** 2.2 (2025)  
**Licencia:** MIT (uso acad√©mico y educativo)

üßæ *"Una IA responsable no reemplaza la mirada humana; la amplifica para crear conocimiento y seguridad en su entorno."*

---

Este texto est√° listo para **copiar y pegar directamente en tu repositorio GitHub** como `README.md` o en la infograf√≠a interactiva.  
Incluye estilo visual, estructura profesional y secciones innovadoras.
