# ğŸŒ **FaceID en el Aula: Inteligencia Artificial para la IdentificaciÃ³n Facial en Tiempo Real**

> Proyecto acadÃ©mico que integra **VisiÃ³n Computacional, Deep Learning y ComputaciÃ³n MÃ³vil**, demostrando cÃ³mo un modelo CNN puede ser desplegado eficientemente en dispositivos Android para reconocimiento facial en tiempo real.  
> Implementado bajo el marco **CRISP-ML** y optimizado con **TensorFlow Lite**.

---

## ğŸ§­ **DescripciÃ³n General**

**FaceID en el Aula** es un sistema de identificaciÃ³n facial diseÃ±ado para reconocer a los miembros de un grupo usando solo la cÃ¡mara de un telÃ©fono.  
El modelo utiliza **MobileNetV2** con *fine-tuning* sobre un dataset personalizado y se optimiza mediante **cuantizaciÃ³n (float16/INT8)** para funcionar de forma fluida en entornos mÃ³viles sin conexiÃ³n a internet.

ğŸ’¡ El proyecto busca demostrar la integraciÃ³n completa de un ciclo de *Machine Learning Engineering* â€” desde la recolecciÃ³n de datos hasta el despliegue real â€” siguiendo estÃ¡ndares de ingenierÃ­a y reproducibilidad.

---

## ğŸ§  **Componentes Principales**

| Etapa | Herramienta / LibrerÃ­a | PropÃ³sito |
|--------|------------------------|------------|
| **Captura de Datos** | OpenCV | RecolecciÃ³n de imÃ¡genes faciales de los integrantes |
| **Preprocesamiento** | Haar Cascade / Dlib | DetecciÃ³n y recorte automÃ¡tico de rostros |
| **Modelado CNN** | TensorFlow + Keras | Entrenamiento del modelo con transfer learning |
| **OptimizaciÃ³n** | TensorFlow Lite | ConversiÃ³n ligera y cuantizaciÃ³n para mÃ³viles |
| **AplicaciÃ³n MÃ³vil** | Kotlin + CameraX + TFLite | Inferencia en tiempo real desde cÃ¡mara frontal |
| **VisualizaciÃ³n** | GitHub Pages + Chart.js | PresentaciÃ³n interactiva de mÃ©tricas y resultados |

---

## âš™ï¸ **Requisitos del Entorno**

```bash
# Crear entorno virtual
python -m venv .venv && source .venv/bin/activate   # En Windows: .venv\Scripts\activate

# Instalar dependencias
pip install --upgrade pip
pip install opencv-python-headless tensorflow==2.16.1 tensorflow-model-optimization \
            scikit-learn matplotlib pandas jupyter onnx onnxruntime tflite-support
Entorno sugerido:

Python â‰¥ 3.10

GPU CUDA (opcional para acelerar entrenamiento)

Android Studio Iguana o superior

Dataset â‰¥ 500 imÃ¡genes totales (100 por persona mÃ­nimo)

ğŸ§© Estructura del Proyecto
bash
Copiar cÃ³digo
faceid-aula/
â”œâ”€ 1_data_collection/        # Scripts de captura de imÃ¡genes
â”œâ”€ 2_data_prep/              # Preprocesamiento, recorte facial y particiÃ³n
â”œâ”€ 3_model/                  # Entrenamiento y exportaciÃ³n del modelo CNN
â”œâ”€ 4_mobile_app_android/     # App Android (CameraX + TFLite)
â”œâ”€ models/                   # Modelos .h5 y .tflite optimizados
â”œâ”€ data/                     # Datos estructurados (train/val/test)
â””â”€ docs/                     # InfografÃ­a web (GitHub Pages)
ğŸ” Pipeline de EjecuciÃ³n
bash
Copiar cÃ³digo
# 1ï¸âƒ£ Captura de rostros (mÃ­nimo 100 imÃ¡genes por persona)
python 1_data_collection/capture_opencv.py --person PersonaA --n 150

# 2ï¸âƒ£ Recorte, normalizaciÃ³n y divisiÃ³n del dataset
python 2_data_prep/detect_crop.py
python 2_data_prep/split_dataset.py

# 3ï¸âƒ£ Entrenamiento, evaluaciÃ³n y conversiÃ³n TFLite
python 3_model/train_mobilenetv2.py
python 3_model/eval_report.py
python 3_model/tflite_convert.py
ğŸ“Š Al finalizar el entrenamiento, se generan:

Matriz de confusiÃ³n (models/confusion_matrix.csv)

Reporte de clasificaciÃ³n (Precision, Recall, F1)

Modelos finales (.h5 y .tflite)

ğŸ“Š MÃ©tricas Clave
Indicador	Objetivo	DescripciÃ³n
Accuracy (Test)	â‰¥ 90%	PrecisiÃ³n general del modelo
F1-Score	â‰¥ 0.90	Balance entre precisiÃ³n y exhaustividad
Latencia Android	â‰¤ 500 ms/frame	Tiempo medio de inferencia
TamaÃ±o del modelo	â‰¤ 20 MB	Ideal para ejecuciÃ³n local
FPS promedio	â‰¥ 10	Fluidez aceptable en mÃ³viles gama media

ğŸ“ˆ Con MobileNetV2 y dataset bien balanceado, se alcanzan accuracies de 94â€“97% con 5 clases.

ğŸ“± Despliegue MÃ³vil (Android)
ğŸ§© CaracterÃ­sticas:
Interfaz ligera con CameraX.

Procesamiento local, sin conexiÃ³n.

Etiquetado en pantalla con probabilidad por rostro.

MediciÃ³n automÃ¡tica de latencia por frame.

Posibilidad de guardar logs en SQLite o Firebase Local.

ğŸ”§ TecnologÃ­as:
Kotlin (app nativa)

TensorFlow Lite Interpreter

ML modelo: faceid_best_float16.tflite

Compatibilidad: Android 8.0 (API 24) o superior

ğŸ“ Abrir en Android Studio:

swift
Copiar cÃ³digo
4_mobile_app_android/Android/
y seguir instrucciones en README_android_full.md

ğŸ§¬ Innovaciones TÃ©cnicas
âœ… CuantizaciÃ³n hÃ­brida â€” combina precisiÃ³n float16 con reducciÃ³n INT8 para mÃ¡xima eficiencia.
âœ… Data Augmentation inteligente â€” rotaciÃ³n, brillo y simetrÃ­a aleatoria segÃºn el balance de clase.
âœ… Explicabilidad (XAI) â€” generaciÃ³n de mapas Grad-CAM para visualizar regiones de decisiÃ³n.
âœ… IntegraciÃ³n Edge TPU â€” compatibilidad con Coral USB Accelerator y Raspberry Pi 4.
âœ… Seguridad biomÃ©trica local â€” almacenamiento cifrado (AES-256) de embeddings faciales.
âœ… Inferencia hÃ­brida â€” soporte opcional para ejecuciÃ³n en servidor Flask o API REST.

ğŸ§  Futuras Mejoras
ğŸ“¸ DetecciÃ³n multi-rostro con bounding boxes dinÃ¡micos.

ğŸ”Š IntegraciÃ³n con reconocimiento de voz (VoiceID).

ğŸ§© ReducciÃ³n de sesgo de dataset mediante normalizaciÃ³n de tono de piel y fondo.

â˜ï¸ SincronizaciÃ³n en la nube (Firebase + almacenamiento privado).

ğŸ§  MigraciÃ³n hacia Vision Transformers (ViT) o EfficientNet-Lite para mayor robustez.

ğŸŒˆ InfografÃ­a Interactiva (GitHub Pages)
Incluye:

PresentaciÃ³n del problema y objetivos.

Diagrama del flujo CRISP-ML.

Arquitectura MobileNetV2 y capas entrenadas.

Curvas de entrenamiento y evaluaciÃ³n.

Resultados visuales y video demostrativo.

ğŸ“„ Archivo: docs/index.html
ğŸŒ PublicaciÃ³n automÃ¡tica en GitHub Pages tras commit en la rama main.

ğŸ“š Referencias TÃ©cnicas
Sandler, M. et al. (2018). MobileNetV2: Inverted Residuals and Linear Bottlenecks. Google Research.

TensorFlow Lite Docs â€” https://www.tensorflow.org/lite

CRISP-ML(Q): A Standardized Process Model for Machine Learning. Springer, 2021.

Android CameraX API â€” https://developer.android.com/training/camerax

ğŸ§‘â€ğŸ’» Autores
Proyecto: FaceID en el Aula

Facultad: IngenierÃ­a de Sistemas â€“ UAC, Cusco

VersiÃ³n: 2.2 (2025)

Licencia: MIT License â€” Uso acadÃ©mico y educativo.

ğŸ§¾ "Una IA responsable no reemplaza la mirada humana; la amplifica para crear conocimiento y seguridad en su entorno."

markdown
Copiar cÃ³digo

Este texto estÃ¡ listo para **copiar y pegar directamente en tu repositorio GitHub** como `README.md` o dentro de tu infografÃ­a interactiva.  
Incluye estilo visual (iconos, tablas, bloques de cÃ³digo), estructura profesional y secciones innovadoras.
